{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldstock_function import yahoo_company_info_downloader\n",
    "from worldstock_function import prep_company_name\n",
    "from utils import country_code_input,country_code_list, refine_dataset_maker\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_input()\n",
    "country_code_list('china')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러나라 혹은 한개의 나라의 yahoo 종목 데이터를 수집하는 코드\n",
    "country_collect_list = ['us','china','japan','uk','india','italy','korea','spain','hongkong','brazil']\n",
    "for country_one in country_collect_list:\n",
    "    a = yahoo_company_info_downloader(country_one)\n",
    "    a.yahoo_dataset_maker(company_option=False)\n",
    "'''\n",
    "a = yahoo_company_info_downloader('china')\n",
    "data = a.yahoo_dataset_maker(company_option=False)\n",
    "data.head(2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러나라 혹은 한개의 나라의 yahoo 종목 데이터를 전처리하여 대표이름을 산출하는 과정\n",
    "country_collect_list = ['us','china','japan','uk','india','italy','korea','spain','hongkong','brazil']\n",
    "for country_one in country_collect_list:\n",
    "    b = prep_company_name(country_one)\n",
    "    b.stock_list_symbol(number_word_option = 2)\n",
    "'''\n",
    "b = prep_company_name('china')\n",
    "name_data = b.stock_list_symbol(number_word_option = 2)\n",
    "name_data.head(3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 여러나라 혹은 한개의 나라의 yahoo 종목 데이터를 통해 산출된 대표이름에 수작업한 데이터를 적용하여 최종전처리를 시행하는 과정\n",
    "country_collect_list = ['us','china','japan','uk','india','italy','korea','spain','hongkong','brazil']\n",
    "for country_one in country_collect_list:\n",
    "    refine_dataset_maker(country_one)\n",
    "#refine_dataset_maker('china')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arrival', 'plc', 'inc', 'mango', 'Kiwi']\n",
      "                 name  Price Stock\n",
      "0     [orange, juice]     34   Yes\n",
      "1             [mango]     24    No\n",
      "2            [banana]     14    No\n",
      "3             [apple]     44   Yes\n",
      "4  [pineapple, juice]     64    No\n",
      "5              [Kiwi]     84   Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[orange, juice]</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[banana]</td>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apple]</td>\n",
       "      <td>44</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[pineapple, juice]</td>\n",
       "      <td>64</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  Price Stock\n",
       "0     [orange, juice]     34   Yes\n",
       "2            [banana]     14    No\n",
       "3             [apple]     44   Yes\n",
       "4  [pineapple, juice]     64    No"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataset/handwork_dataset/remove_one_word_dataset.txt') as word_file:\n",
    "    oneword = word_file.read().splitlines()\n",
    "print(oneword)\n",
    "oneword\n",
    "import pandas as pd\n",
    "fruit_list = [ (['orange','juice'], 34, 'Yes' ) ,\n",
    "             (['mango'], 24, 'No' ) ,\n",
    "             (['banana'], 14, 'No' ) ,\n",
    "             (['apple'], 44, 'Yes' ) ,\n",
    "             (['pineapple','juice'], 64, 'No') ,\n",
    "             (['Kiwi'], 84, 'Yes')  ]\n",
    "#Create a DataFrame object\n",
    "df = pd.DataFrame(fruit_list, columns = \n",
    "                  ['name', 'Price', 'Stock']) \n",
    "print(df)\n",
    "df[[False if len(i)==1 and i[0] in oneword else True for i in df['name'] ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oken'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accented_string = 'öken'\n",
    "# accented_string is of type 'unicode'\n",
    "import unidecode\n",
    "unaccented_string = unidecode.unidecode(accented_string)\n",
    "# unaccented_string contains 'Malaga'and is of type 'str'\n",
    "unaccented_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Sort And Remove Duplicate Lines Start\n",
      "File Sort End\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "print('File Sort And Remove Duplicate Lines Start') \n",
    "w = open(\"C:/Users/BIG-LGY/Downloads/words_470k_new.txt\", 'w', encoding='UTF8')\n",
    "r = open(\"C:/Users/BIG-LGY/Downloads/words_470k.txt\", 'r', encoding='UTF8')\n",
    "#파일에서 읽은 라인들을 리스트로 읽어들임\n",
    "lines = r.readlines()\n",
    "lines = [i.lower() for i in lines]\n",
    "lines = [unidecode.unidecode(i) for i in lines]\n",
    "#Set에 넣어서 중복 제거 후 다시 리스트 변환\n",
    "lines = list(set(lines))\n",
    "#리스트 정렬\n",
    "lines.sort()\n",
    " \n",
    "#정렬,중복제거한 리스트 파일 쓰기\n",
    "for line in lines :\n",
    "    w.write(line)\n",
    " \n",
    "#파일 닫기\n",
    "w.close()\n",
    "r.close()\n",
    " \n",
    "print('File Sort End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4883204\n"
     ]
    }
   ],
   "source": [
    "f = open(\"C:/Users/BIG-LGY/Downloads/words_470k.txt\", 'r')\n",
    "data = f.read()\n",
    "print(len(data))\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271ac903d638a034f30d392206313ddfc44850c43ffc24ecd523e49d8ee807c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
